"""
Multimodal Step 2: Audio - Whisperë¡œ ìŒì„± ì¸ì‹

pip install openai-whisper

ì£¼ì˜: WhisperëŠ” í° ëª¨ë¸ì´ë¯€ë¡œ ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤
"""

import os


def whisper_basic_example():
    """Whisper ê¸°ë³¸ ì‚¬ìš©ë²•"""
    print("=== Whisper ìŒì„± ì¸ì‹ ===\n")

    print("ì„¤ì¹˜:")
    print("  pip install openai-whisper")
    print("  pip install ffmpeg-python")
    print()

    print("ì‚¬ìš©ë²•:")
    code = '''import whisper

# ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ 1íšŒ ë‹¤ìš´ë¡œë“œ)
model = whisper.load_model("base")  # tiny, base, small, medium, large

# ìŒì„± íŒŒì¼ â†’ í…ìŠ¤íŠ¸
result = model.transcribe("audio.mp3", language="ko")

print(result["text"])
'''
    print(code)
    print()


def whisper_models():
    """Whisper ëª¨ë¸ ë¹„êµ"""
    print("=== Whisper ëª¨ë¸ ===\n")

    models = [
        ("tiny", "39M", "ë¹ ë¦„", "ë‚®ìŒ", "1GB RAM"),
        ("base", "74M", "ë¹ ë¦„", "ì¤‘ê°„", "1GB RAM"),
        ("small", "244M", "ì¤‘ê°„", "ì¢‹ìŒ", "2GB RAM"),
        ("medium", "769M", "ëŠë¦¼", "ìš°ìˆ˜", "5GB RAM"),
        ("large", "1550M", "ë§¤ìš° ëŠë¦¼", "ìµœê³ ", "10GB RAM"),
    ]

    print("ëª¨ë¸    | í¬ê¸°  | ì†ë„      | í’ˆì§ˆ | ë©”ëª¨ë¦¬")
    print("-" * 55)

    for name, size, speed, quality, memory in models:
        print(f"{name:7} | {size:5} | {speed:9} | {quality:4} | {memory}")

    print("\nğŸ’¡ ê¶Œì¥: base (í•œêµ­ì–´ë„ ì˜ ì¸ì‹)")
    print()


def use_cases():
    """ì‹¤ë¬´ í™œìš© ì‚¬ë¡€"""
    print("=== ì‹¤ë¬´ í™œìš© ===\n")

    cases = [
        "íšŒì˜ ë…¹ìŒ â†’ í…ìŠ¤íŠ¸ ë³€í™˜ â†’ ìš”ì•½",
        "ìœ íŠœë¸Œ ì˜ìƒ â†’ ìë§‰ ìƒì„±",
        "ìŒì„± ëª…ë ¹ â†’ í…ìŠ¤íŠ¸ â†’ LLM ì²˜ë¦¬",
        "íŒŸìºìŠ¤íŠ¸ â†’ í…ìŠ¤íŠ¸ â†’ ê²€ìƒ‰ ê°€ëŠ¥",
    ]

    for i, case in enumerate(cases, 1):
        print(f"{i}. {case}")

    print()


def whisper_with_llm():
    """Whisper + LLM ì¡°í•©"""
    print("=== Whisper + LLM ===\n")

    workflow = '''
1. ìŒì„± ë…¹ìŒ (audio.mp3)
   â†“
2. Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
   "ì˜¤ëŠ˜ íšŒì˜ì—ì„œ ë…¼ì˜ëœ ì•¡ì…˜ ì•„ì´í…œì€..."
   â†“
3. LLMìœ¼ë¡œ ìš”ì•½
   "ì•¡ì…˜ ì•„ì´í…œ: 1) ... 2) ..."
'''

    print(workflow)

    code = '''# ì˜ˆì œ ì½”ë“œ
import whisper
from langchain_community.llms import Ollama

# 1. ìŒì„± â†’ í…ìŠ¤íŠ¸
model = whisper.load_model("base")
result = model.transcribe("meeting.mp3", language="ko")
text = result["text"]

# 2. í…ìŠ¤íŠ¸ â†’ ìš”ì•½
llm = Ollama(model="llama3")
summary = llm.invoke(f"ë‹¤ìŒ íšŒì˜ë¡ì„ ìš”ì•½í•´ì¤˜:\\n{text}")

print(summary)
'''

    print("\nì½”ë“œ:")
    print(code)
    print()


if __name__ == "__main__":
    print("ğŸ¤ Whisper ìŒì„± ì¸ì‹\n")
    print("=" * 60)

    whisper_basic_example()
    print("-" * 60)
    whisper_models()
    print("-" * 60)
    use_cases()
    print("-" * 60)
    whisper_with_llm()

    print("=" * 60)
    print("\nâœ… Whisper ì´í•´ ì™„ë£Œ!")
    print("\nğŸ’¡ í•µì‹¬:")
    print("  - Whisper = ìŒì„± â†’ í…ìŠ¤íŠ¸")
    print("  - LLM = í…ìŠ¤íŠ¸ ì²˜ë¦¬")
    print("  - ì¡°í•© = ìŒì„± ê¸°ë°˜ AI")
    print()

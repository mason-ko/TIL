"""
MLOps Step 1: FastAPI μ„λ²„

pip install fastapi uvicorn langchain-community
"""

from fastapi import FastAPI
from pydantic import BaseModel
from langchain_community.llms import Ollama

app = FastAPI(title="LLM API")
llm = Ollama(model="llama3")


class ChatRequest(BaseModel):
    message: str


class ChatResponse(BaseModel):
    response: str


@app.get("/")
def root():
    return {"message": "LLM API Server", "status": "running"}


@app.post("/chat", response_model=ChatResponse)
def chat(request: ChatRequest):
    """μ±„ν… μ—”λ“ν¬μΈνΈ"""
    response = llm.invoke(request.message)
    return ChatResponse(response=response)


@app.get("/health")
def health():
    """ν—¬μ¤ μ²΄ν¬"""
    return {"status": "healthy"}


if __name__ == "__main__":
    import uvicorn

    print("π€ LLM API μ„λ²„ μ‹μ‘...")
    print("   http://localhost:8000")
    print("   http://localhost:8000/docs (Swagger UI)")

    uvicorn.run(app, host="0.0.0.0", port=8000)

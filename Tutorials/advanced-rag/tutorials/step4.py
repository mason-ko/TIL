"""
Advanced RAG Step 4: Contextual Compression

pip install chromadb
"""

import chromadb


def compress_context(docs, query):
    """ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ì‹œë®¬ë ˆì´ì…˜"""
    compressed = []

    for doc in docs:
        # ê°„ë‹¨í•œ ì••ì¶•: ì¿¼ë¦¬ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ë¬¸ì¥ë§Œ ì¶”ì¶œ
        sentences = doc.split('.')
        relevant = [s.strip() for s in sentences if query.lower() in s.lower()]

        if relevant:
            compressed.append('. '.join(relevant) + '.')

    return compressed


def main():
    print("=== Contextual Compression ===\n")

    # ë°ì´í„° (ê¸´ ë¬¸ì„œ ì‹œë®¬ë ˆì´ì…˜)
    docs = [
        """LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.
        ë‹¤ì–‘í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. Chain, Agent, Memory ë“±ì´ ìˆìŠµë‹ˆë‹¤.
        LangGraphëŠ” LangChain ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
        ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.""",

        """Vector DatabaseëŠ” ì„ë² ë”© ì €ì¥ì†Œì…ë‹ˆë‹¤.
        ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤. ChromaDB, Pinecone ë“±ì´ ìˆìŠµë‹ˆë‹¤.
        RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ì…ë‹ˆë‹¤.""",

        """OllamaëŠ” ë¡œì»¬ LLM ì‹¤í–‰ ë„êµ¬ì…ë‹ˆë‹¤.
        Llama 3, Mistral ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.
        API ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ì™„ì „ ë¬´ë£Œì…ë‹ˆë‹¤."""
    ]

    # ChromaDB
    client = chromadb.Client()
    try:
        client.delete_collection("docs")
    except:
        pass

    collection = client.create_collection("docs")
    collection.add(documents=docs, ids=[f"doc{i}" for i in range(len(docs))])

    print(f"âœ… {len(docs)}ê°œ ë¬¸ì„œ ì €ì¥\n")
    print("="*60)

    # ê²€ìƒ‰
    query = "LangGraph"
    print(f"ğŸ” ì§ˆë¬¸: {query}\n")

    results = collection.query(query_texts=[query], n_results=2)

    # ì••ì¶• ì „
    print("ğŸ“„ ì••ì¶• ì „ (ì „ì²´ ë¬¸ì„œ):")
    for i, doc in enumerate(results['documents'][0], 1):
        print(f"\n   ë¬¸ì„œ {i} ({len(doc)}ì):")
        print(f"   {doc}")

    # ì••ì¶• í›„
    compressed = compress_context(results['documents'][0], query)

    print("\n" + "="*60)
    print("âœ‚ï¸ ì••ì¶• í›„ (ê´€ë ¨ ë¶€ë¶„ë§Œ):")
    for i, doc in enumerate(compressed, 1):
        print(f"\n   ë¬¸ì„œ {i} ({len(doc)}ì):")
        print(f"   {doc}")

    # í†µê³„
    original_length = sum(len(d) for d in results['documents'][0])
    compressed_length = sum(len(d) for d in compressed)
    reduction = (1 - compressed_length / original_length) * 100

    print(f"\nğŸ“Š ì••ì¶• í†µê³„:")
    print(f"   ì›ë³¸: {original_length}ì")
    print(f"   ì••ì¶•: {compressed_length}ì")
    print(f"   ì ˆê°: {reduction:.1f}%")

    print("\nğŸ’¡ í•µì‹¬: í† í° ì ˆê° â†’ ë¹„ìš© ê°ì†Œ, ì†ë„ í–¥ìƒ")
    print("ğŸ“š ë‹¤ìŒ: step5.py - Parent Document Retrieval\n")


if __name__ == "__main__":
    main()

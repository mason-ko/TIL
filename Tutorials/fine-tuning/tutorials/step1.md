# Step 1: LoRA 기초 - 효율적인 Fine-tuning

## 목표

- Fine-tuning 개념 이해
- LoRA 원리 학습
- 필요한 하드웨어 이해

## Fine-tuning이란?

**사전 학습된 모델을 내 데이터로 추가 학습**

```python
Before:
Q: "우리 회사 정책은?"
A: "모르겠습니다" ❌

After (Fine-tuned):
Q: "우리 회사 정책은?"
A: "근무시간은 9-6시입니다" ✅
```

## LoRA란?

**Low-Rank Adaptation** - 작은 어댑터만 학습

```
Full Fine-tuning:
- 모든 파라미터 업데이트
- GPU 메모리: 70B 모델 = 280GB
- 시간: 며칠

LoRA:
- 작은 어댑터만 학습 (1-2%)
- GPU 메모리: 70B 모델 = 40GB
- 시간: 몇 시간
- 품질: 90% 유지
```

## 필요한 것

### 하드웨어
```
7B 모델: RTX 3090 (24GB)
13B 모델: RTX 4090 (24GB) + QLoRA
70B 모델: A100 (40GB) x 2
```

### 데이터
```
최소: 1,000개
권장: 10,000개
형식: {"instruction": "...", "output": "..."}
```

## 언제 Fine-tuning?

✅ **필요한 경우:**
- 도메인 특화 (의료, 법률)
- 회사 코딩 스타일
- 저자원 언어

❌ **불필요한 경우:**
- 프롬프트로 해결 가능
- 데이터 부족 (< 1,000개)
- GPU 없음

## 핵심 요약

- **LoRA = 효율적 Fine-tuning**
- **GPU 메모리 80% 절감**
- **품질 90% 유지**

---

**다음**: step2 - 실제 LoRA 학습

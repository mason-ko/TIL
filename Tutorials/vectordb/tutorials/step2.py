"""
Vector DB Step 2: ì„ë² ë”© ëª¨ë¸ ì„ íƒ

pip install chromadb sentence-transformers
"""

import chromadb
from chromadb.utils import embedding_functions


def example1_default_embedding():
    """ì˜ˆì œ 1: ê¸°ë³¸ ì„ë² ë”© (ìë™)"""
    print("=== ê¸°ë³¸ ì„ë² ë”© ===\n")

    client = chromadb.Client()
    collection = client.create_collection("default")

    docs = ["Python í”„ë¡œê·¸ë˜ë°", "ìë°”ìŠ¤í¬ë¦½íŠ¸ ê°œë°œ"]
    collection.add(documents=docs, ids=["d1", "d2"])

    print("âœ… ê¸°ë³¸ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (all-MiniLM-L6-v2)\n")


def example2_multilingual():
    """ì˜ˆì œ 2: ë‹¤êµ­ì–´ ì„ë² ë”© (í•œêµ­ì–´ ìµœì í™”)"""
    print("=== ë‹¤êµ­ì–´ ì„ë² ë”© ===\n")

    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="paraphrase-multilingual-MiniLM-L12-v2"
    )

    client = chromadb.Client()
    collection = client.create_collection(
        "multilingual",
        embedding_function=sentence_transformer_ef
    )

    docs = [
        "ê°•ì•„ì§€ê°€ ê³µì›ì—ì„œ ë›°ì–´ë†€ê³  ìˆë‹¤",
        "ê³ ì–‘ì´ê°€ ì°½ê°€ì— ì•‰ì•„ìˆë‹¤",
        "Dog is playing in the park"
    ]

    collection.add(documents=docs, ids=[f"d{i}" for i in range(len(docs))])

    # í•œêµ­ì–´ë¡œ ê²€ìƒ‰
    results = collection.query(query_texts=["ê°œê°€ ë…¸ëŠ” ëª¨ìŠµ"], n_results=2)

    print("ê²€ìƒ‰ì–´: 'ê°œê°€ ë…¸ëŠ” ëª¨ìŠµ'")
    for doc in results['documents'][0]:
        print(f"  - {doc}")
    print("\nâœ… í•œêµ­ì–´ë„ ì˜ ì°¾ìŒ!\n")


def example3_custom_openai():
    """ì˜ˆì œ 3: OpenAI ì„ë² ë”© (ê³ í’ˆì§ˆ, ìœ ë£Œ)"""
    print("=== OpenAI ì„ë² ë”© (ì°¸ê³ ìš©) ===\n")

    print("OpenAI Embeddings:")
    print("  - ëª¨ë¸: text-embedding-3-small")
    print("  - ì°¨ì›: 1536")
    print("  - í’ˆì§ˆ: ë§¤ìš° ë†’ìŒ")
    print("  - ë¹„ìš©: $0.02 / 1M tokens")
    print("\nì‚¬ìš©ë²•:")
    print("  openai_ef = embedding_functions.OpenAIEmbeddingFunction(")
    print("      api_key='your-key',")
    print("      model_name='text-embedding-3-small'")
    print("  )\n")


def compare_models():
    """ì„ë² ë”© ëª¨ë¸ ë¹„êµ"""
    print("=== ì„ë² ë”© ëª¨ë¸ ë¹„êµ ===\n")

    models = [
        ("all-MiniLM-L6-v2", "384ì°¨ì›", "ì˜ì–´ ì¤‘ì‹¬", "ê¸°ë³¸ê°’"),
        ("paraphrase-multilingual", "384ì°¨ì›", "ë‹¤êµ­ì–´", "í•œêµ­ì–´ ì¶”ì²œ"),
        ("text-embedding-3-small", "1536ì°¨ì›", "ìµœê³  í’ˆì§ˆ", "ìœ ë£Œ"),
    ]

    print("ëª¨ë¸               | ì°¨ì›   | íŠ¹ì§•      | ìš©ë„")
    print("-" * 60)
    for name, dim, feature, use in models:
        print(f"{name:20} | {dim:6} | {feature:10} | {use}")

    print()


if __name__ == "__main__":
    example1_default_embedding()
    print("-" * 60)
    example2_multilingual()
    print("-" * 60)
    example3_custom_openai()
    print("-" * 60)
    compare_models()

    print("=" * 60)
    print("\nâœ… ì„ë² ë”© ëª¨ë¸ ì´í•´ ì™„ë£Œ!")
    print("\nğŸ’¡ ê¶Œì¥: í•œêµ­ì–´ â†’ paraphrase-multilingual")
    print("ğŸ“š ë‹¤ìŒ: step3.py - RAG ì‹¤ì „ êµ¬í˜„\n")
